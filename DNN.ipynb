{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZxVy5U4ZR1BJlqaliX-oIJ8DnilrqfTe","authorship_tag":"ABX9TyOo/1srfanzhsHLBxtczWv7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmab9M9npP0b","executionInfo":{"status":"ok","timestamp":1711861992757,"user_tz":-540,"elapsed":48260,"user":{"displayName":"장민석","userId":"13326554217008561699"}},"outputId":"e3991511-29c6-4db8-86d1-951644b7adb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss 0.37054824879151266\n","Epoch 2, Loss 0.3300261752068541\n","Epoch 3, Loss 0.32619711956905045\n","Epoch 4, Loss 0.3236861278310077\n","Epoch 5, Loss 0.3213376080261842\n","Epoch 6, Loss 0.3204278574872563\n","Epoch 7, Loss 0.3177044071996485\n","Epoch 8, Loss 0.3154513647538105\n","Epoch 9, Loss 0.3139807550279239\n","Epoch 10, Loss 0.31196566987356156\n","Epoch 11, Loss 0.3099340831732932\n","Epoch 12, Loss 0.3079038630460055\n","Epoch 13, Loss 0.3062124520312739\n","Epoch 14, Loss 0.30439794404816084\n","Epoch 15, Loss 0.3027121424447489\n","Epoch 16, Loss 0.3011080264817667\n","Epoch 17, Loss 0.29953231913897826\n","Epoch 18, Loss 0.2980346078181085\n","Epoch 19, Loss 0.2963746211000981\n","Epoch 20, Loss 0.2944387579919728\n","Accuracy: 85.50157487830487%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def adult_dataset(fname):\n","    columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n","    data = pd.read_csv(fname, names=columns, sep=',\\s', na_values=\"?\", engine='python')\n","    data.dropna(inplace=True)\n","\n","    for col in ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'income']:\n","        le = LabelEncoder()\n","        data[col] = le.fit_transform(data[col])\n","\n","    X = data.drop('income', axis=1).values\n","    y = data['income'].values\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    return X_train, X_test, y_train, y_test\n","\n","class AdultDataset(Dataset):\n","    def __init__(self, features, labels):\n","        self.features = features\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.features[idx], dtype=torch.float).to(device), torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n","\n","class DNNModel(nn.Module):\n","    def __init__(self):\n","        super(DNNModel, self).__init__()\n","        self.layer1 = nn.Linear(14,64)\n","        self.layer2 = nn.Linear(64,32)\n","        self.layer3 = nn.Linear(32,16)\n","        self.layer4 = nn.Linear(16,2)\n","        self.relu = nn.ReLU()\n","    def forward(self,x):\n","        x = self.relu(self.layer1(x))\n","        x = self.relu(self.layer2(x))\n","        x = self.relu(self.layer3(x))\n","        x = self.layer4(x)\n","        return x\n","\n","X_train, X_test, y_train, y_test = adult_dataset('/content/drive/My Drive/adult.data')\n","train_dataset = AdultDataset(X_train, y_train)\n","test_dataset = AdultDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","model = DNNModel().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","epochs =20\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss=0.0\n","    for features,labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs=model(features)\n","        loss=criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss+=loss.item()\n","    print(f'Epoch {epoch + 1}, Loss {running_loss/len(train_loader)}')\n","\n","model.eval()\n","correct=0\n","total=0\n","with torch.no_grad():\n","    for features, labels in test_loader:\n","        outputs = model(features)\n","        _, predicted = torch.max(outputs.data,1)\n","        total+=labels.size(0)\n","        correct+=(predicted==labels).sum().item()\n","accuracy =100*correct/total\n","print(f'Accuracy: {accuracy}%')\n","\n","\n"]}]}